{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f65a63d-a922-4385-a2de-19e28b67a15d",
   "metadata": {},
   "source": [
    "# Лабораторная 6. Градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b947d2-f58b-43b1-b282-c2f2b0440354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivanmipt/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# используемые библиотеки\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41ccaa-bbc3-4a81-ba7f-d24908f1eb17",
   "metadata": {},
   "source": [
    "## 1. Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2955233-1acb-4afa-a7cc-bf9d80345bbb",
   "metadata": {},
   "source": [
    "### 1.1 Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85862b7-ed2b-4e61-bd90-5cbdedc2628d",
   "metadata": {},
   "source": [
    "Кросс-валидация (cross-validation) — это метод оценки производительности модели машинного обучения, который позволяет избежать переобучения и получить более надежную оценку её качества. Вместо разделения данных ***на одну обучающую и одну тестовую выборки***, как в случае с обычной проверкой на тестовых данных, кросс-валидация использует ***несколько различных разбиений данных*** для обучения и тестирования.\n",
    "\n",
    "***K-кратная кросс-валидация (K-fold cross-validation)***: \n",
    "\n",
    "1. Данные делятся на K равных частей (фолдов).\n",
    "2. Модель обучается K раз: каждый раз одна из частей используется как тестовая выборка, а остальные K-1 части — как обучающая.\n",
    "3. Результаты усредняются для получения окончательной оценки.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa1eb6-4520-409d-8678-c19b480d580d",
   "metadata": {},
   "source": [
    "Предположим, у нас есть набор данных с 1000 объектами, и мы хотим оценить качество логистической регрессии для задачи бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be9c72a-ca8e-4dbf-895e-f10657b39334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценки точности на каждом фолде: [0.855 0.855 0.875 0.865 0.865]\n",
      "Средняя точность: 0.8630000000000001\n"
     ]
    }
   ],
   "source": [
    "# Генерируем синтетические данные\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Создаем модель логистической регрессии\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Инициализируем K-кратную кросс-валидацию с 5 фолдами\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Выполняем кросс-валидацию\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Оценки точности на каждом фолде:\", scores)\n",
    "print(\"Средняя точность:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d9d72-255e-46a7-b184-af9e3f52903d",
   "metadata": {},
   "source": [
    "***Плюсы:***\n",
    "\n",
    "1. Меньший риск переобучения : Поскольку модель тестируется на нескольких подмножествах данных, вероятность переобучения снижается.\n",
    "2. Более эффективное использование данных : Все данные используются как для обучения, так и для тестирования.\n",
    "3. Устойчивость к случайным разбиениям : Усреднение результатов по нескольким фолдам делает оценку более стабильной.\n",
    "\n",
    "***Минусы:***\n",
    "\n",
    "1. Высокая вычислительная сложность : Требуется обучить модель несколько раз.\n",
    "2. Зависимость от размера фолдов : Если фолды слишком маленькие, оценка может быть неточной.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653d9c4-6639-411a-8b7e-d1fa0f5f7758",
   "metadata": {},
   "source": [
    "### 1.2 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbcdcc-f3bb-4159-85cc-cf2632b6932d",
   "metadata": {},
   "source": [
    "***Grid Search  (или \"поиск по сетке\")*** — это метод подбора гиперпараметров модели, при котором мы задаем множество возможных значений для каждого гиперпараметра и перебираем все возможные комбинации этих значений. Для каждой комбинации модель обучается на обучающих данных, а затем оценивается на тестовых или валидационных данных. После этого выбирается та комбинация гиперпараметров, которая дает лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769a33c6-f54e-44ae-b4bc-3b7443b43381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Лучшая точность на кросс-валидации: 0.9785714285714286\n",
      "Точность на тестовой выборке: 1.0\n",
      "Средняя точность по кросс-валидации на всех данных: 0.9720634920634922\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определяем модель\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Задаем сетку гиперпараметров для перебора\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Количество деревьев\n",
    "    'max_depth': [None, 10, 20, 30],  # Максимальная глубина дерева\n",
    "    'min_samples_split': [2, 5, 10],  # Минимальное количество образцов для разделения узла\n",
    "    'min_samples_leaf': [1, 2, 4]     # Минимальное количество образцов в листе\n",
    "}\n",
    "\n",
    "# Инициализируем GridSearchCV с использованием кросс-валидации\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Обучаем модель на обучающей выборке\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучшая точность на кросс-валидации:\", grid_search.best_score_)\n",
    "\n",
    "# Оцениваем качество модели на тестовой выборке\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Точность на тестовой выборке:\", test_accuracy)\n",
    "\n",
    "# Дополнительно: оцениваем качество модели с помощью кросс-валидации на всех данных\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Средняя точность по кросс-валидации на всех данных:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a572d1-2637-47c9-ab2d-c5d5c3945f15",
   "metadata": {},
   "source": [
    "***Плюсы:***\n",
    "\n",
    "1. Простота реализации : Алгоритм простой и понятный.\n",
    "2. Полный перебор : Все возможные комбинации гиперпараметров проверяются, что гарантирует нахождение оптимального решения (если сетка достаточно плотная).\n",
    "     \n",
    "\n",
    "***Минусы:***\n",
    "\n",
    "1. Высокая вычислительная сложность : Если количество гиперпараметров велико или их диапазоны широки, число комбинаций может стать огромным.\n",
    "2. Неэффективность : Многие комбинации могут быть неинтересными или бессмысленными, но они всё равно проверяются.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93075cc1-27e3-4b59-bd22-a00e36975ac2",
   "metadata": {},
   "source": [
    "### 1.3 Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bbdbc-e8b7-4d13-b8f4-49ceaaa8b31f",
   "metadata": {},
   "source": [
    "***Optuna***  — это современная библиотека для подбора гиперпараметров, которая использует Bayesian Optimization  и другие продвинутые методы для эффективного поиска оптимальных значений гиперпараметров. В отличие от Grid Search или Randomized Search, которые перебирают значения из заранее заданных сеток или случайно выбирают их, Optuna адаптивно находит лучшие комбинации гиперпараметров, учитывая предыдущие результаты. \n",
    "\n",
    "\n",
    "1. Optuna использует алгоритмы, такие как Tree-structured Parzen Estimator (TPE) и Bayesian Optimization, что делает её более эффективной, особенно для сложных задач.\n",
    "2. Optuna может автоматически прерывать вычисления для неперспективных наборов гиперпараметров (early stopping).\n",
    "3. Optuna легко интегрируется с популярными фреймворками машинного обучения, такими как scikit-learn, TensorFlow, PyTorch и др.\n",
    "4. Optuna поддерживает параллельный поиск гиперпараметров, что позволяет использовать несколько ядер процессора или даже распределенные системы.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95594494-9858-4ab9-9cda-35e9c4749560",
   "metadata": {},
   "source": [
    "Дан датасет, со следующими признаками.\n",
    "\n",
    "1. ApplicationDate: Loan application date\n",
    "2. Age: Applicant's age\n",
    "3. AnnualIncome: Yearly income\n",
    "4. CreditScore: Creditworthiness score\n",
    "5. EmploymentStatus: Job situation\n",
    "6. EducationLevel: Highest education attained\n",
    "7. Experience: Work experience\n",
    "8. LoanAmount: Requested loan size\n",
    "9. LoanDuration: Loan repayment period\n",
    "10. MaritalStatus: Applicant's marital state\n",
    "11. NumberOfDependents: Number of dependents\n",
    "12. HomeOwnershipStatus: Homeownership type\n",
    "13. MonthlyDebtPayments: Monthly debt obligations\n",
    "14. CreditCardUtilizationRate: Credit card usage percentage\n",
    "15. NumberOfOpenCreditLines: Active credit lines\n",
    "16. NumberOfCreditInquiries: Credit checks count\n",
    "17. DebtToIncomeRatio: Debt to income proportion\n",
    "18. BankruptcyHistory: Bankruptcy records\n",
    "19. LoanPurpose: Reason for loan\n",
    "20. PreviousLoanDefaults: Prior loan defaults\n",
    "21. PaymentHistory: Past payment behavior\n",
    "22. LengthOfCreditHistory: Credit history duration\n",
    "23. SavingsAccountBalance: Savings account amount\n",
    "24. CheckingAccountBalance: Checking account funds\n",
    "25. TotalAssets: Total owned assets\n",
    "26. TotalLiabilities: Total owed debts\n",
    "27. MonthlyIncome: Income per month\n",
    "28. UtilityBillsPaymentHistory: Utility payment record\n",
    "29. JobTenure: Job duration\n",
    "30. NetWorth: Total financial worth\n",
    "31. BaseInterestRate: Starting interest rate\n",
    "32. InterestRate: Applied interest rate\n",
    "33. MonthlyLoanPayment: Monthly loan payment\n",
    "34. TotalDebtToIncomeRatio: Total debt against income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea00963-32ee-46e7-a7fa-d1050503b374",
   "metadata": {},
   "source": [
    "Также датсет содержит информацию:\n",
    "1. LoanApproved: Loan approval status - ***будет ли кредит одобрен (для задачи классификации).***\n",
    "2. RiskScore: Risk assessment score - ***оценка риска (для задачи регрессии).***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce95b9a-0ca2-4d66-b6c1-982e19148605",
   "metadata": {},
   "source": [
    "### Задача 1 (3 балла)\n",
    "\n",
    "Давайте решим задачу бинарной классификации (будет выдан кредит или нет). \n",
    "\n",
    "***Не забудьте удалить столбец RiskScore!***\n",
    "\n",
    "1. Разбейте выборку на обучающую и тестовую. \n",
    "2. Подберите оптимальные гиперпараметры с помощью кросс-валидации и optuna на обучающей выборке.\n",
    "3. Расчитайте F1-score на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e611b-e923-442e-8938-424c9ca65794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98dc82d6-10b8-45fc-8866-bfd31abdc4f5",
   "metadata": {},
   "source": [
    "## 2. Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdae584-2017-4083-8f41-77c7ad050eb7",
   "metadata": {},
   "source": [
    "### 2.1 CatboostClassifier\n",
    "\n",
    "***CatBoostClassifier***  — это мощный алгоритм машинного обучения из библиотеки CatBoost , разработанной компанией Yandex. Он является частью фреймворка CatBoost, который специализируется на обработке категориальных признаков без необходимости их предварительного кодирования (например, с помощью One-Hot Encoding). CatBoost использует градиентный бустинг над деревьями решений и показывает высокую производительность на задачах классификации. \n",
    "***Основные особенности CatboostClassifier***: \n",
    "\n",
    "1. Автоматическая обработка категориальных признаков : CatBoost может работать с категориальными признаками напрямую.\n",
    "2. Снижение переобучения : CatBoost использует методы, такие как перестановочный тест и порядковое целевое кодирование.\n",
    "3. Высокая скорость обучения : Библиотека оптимизирована для быстрого обучения даже на больших объемах данных.\n",
    "4. Поддержка многозадачности : CatBoost может обучаться на нескольких задачах одновременно.\n",
    "5. Встроенная кросс-валидация и подбор гиперпараметров .\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d85bf93-f7c4-4ad1-bc91-e3fc2ec54f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6271690\ttotal: 1.15ms\tremaining: 114ms\n",
      "10:\tlearn: 0.3004846\ttotal: 10.9ms\tremaining: 88.1ms\n",
      "20:\tlearn: 0.1571604\ttotal: 17.7ms\tremaining: 66.5ms\n",
      "30:\tlearn: 0.0947066\ttotal: 23.1ms\tremaining: 51.3ms\n",
      "40:\tlearn: 0.0657784\ttotal: 28.1ms\tremaining: 40.5ms\n",
      "50:\tlearn: 0.0494676\ttotal: 32.6ms\tremaining: 31.3ms\n",
      "60:\tlearn: 0.0405709\ttotal: 36.7ms\tremaining: 23.5ms\n",
      "70:\tlearn: 0.0350401\ttotal: 40.8ms\tremaining: 16.7ms\n",
      "80:\tlearn: 0.0304118\ttotal: 45.1ms\tremaining: 10.6ms\n",
      "90:\tlearn: 0.0280984\ttotal: 49ms\tremaining: 4.85ms\n",
      "99:\tlearn: 0.0266610\ttotal: 52.2ms\tremaining: 0us\n",
      "Точность модели: 1.0000\n",
      "NumFeature1: 28.3813\n",
      "NumFeature2: 27.5961\n",
      "CatFeature1: 11.2484\n",
      "CatFeature2: 32.7742\n"
     ]
    }
   ],
   "source": [
    "# Генерация синтетического датасета\n",
    "np.random.seed(42)\n",
    "\n",
    "# Числовые признаки\n",
    "num_feature_1 = np.random.normal(5, 2, 1000)  # Признак 1: нормальное распределение\n",
    "num_feature_2 = np.random.uniform(0, 10, 1000)  # Признак 2: равномерное распределение\n",
    "\n",
    "# Категориальные признаки\n",
    "cat_feature_1 = np.random.choice(['A', 'B', 'C'], size=1000)  # Категориальный признак 1\n",
    "cat_feature_2 = np.random.choice(['X', 'Y'], size=1000)       # Категориальный признак 2\n",
    "\n",
    "# Целевая переменная (зависимость от признаков)\n",
    "target = []\n",
    "for i in range(1000):\n",
    "    if num_feature_1[i] > 6 and cat_feature_1[i] in ['A', 'B']:  # Правило для класса 1\n",
    "        target.append(1)\n",
    "    elif num_feature_2[i] < 5 and cat_feature_2[i] == 'X':      # Правило для класса 1\n",
    "        target.append(1)\n",
    "    else:\n",
    "        target.append(0)\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'NumFeature1': num_feature_1,\n",
    "    'NumFeature2': num_feature_2,\n",
    "    'CatFeature1': cat_feature_1,\n",
    "    'CatFeature2': cat_feature_2,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop(columns=['Target'])\n",
    "y = data['Target']\n",
    "\n",
    "# Указание категориальных признаков\n",
    "categorical_features = ['CatFeature1', 'CatFeature2']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание объектов Pool для CatBoost\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=categorical_features)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=categorical_features)\n",
    "\n",
    "# Инициализация модели CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,        # Количество итераций (деревьев)\n",
    "    depth=6,               # Максимальная глубина дерева\n",
    "    learning_rate=0.1,     # Скорость обучения\n",
    "    loss_function='Logloss',  # Функция потерь для бинарной классификации\n",
    "    verbose=10             # Вывод информации каждые 10 итераций\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(train_pool)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "predictions = model.predict(test_pool)\n",
    "\n",
    "# Оценка качества модели\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Точность модели: {accuracy:.4f}\")\n",
    "\n",
    "# Важность признаков\n",
    "feature_importances = model.get_feature_importance()\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d548d-960a-46d5-af0d-6b9ccd43c71a",
   "metadata": {},
   "source": [
    "### Задача 2 (3 балла)\n",
    "\n",
    "Решите предыдущую задачу, используя CatboostClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a546b-4691-4c25-9cfd-702753ebfffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd008478-7bbe-411d-bb0a-3a61d1ab9234",
   "metadata": {},
   "source": [
    "### 2.2 CatboostRegressor\n",
    "\n",
    "***CatBoostRegressor***  — это алгоритм регрессии из библиотеки CatBoost , разработанной компанией Yandex. Он является частью фреймворка CatBoost, который специализируется на градиентном бустинге над деревьями решений и поддерживает как числовые, так и категориальные признаки без необходимости их предварительного кодирования (например, One-Hot Encoding). CatBoostRegressor используется для решения задач регрессии, где целевая переменная является непрерывной. \n",
    "***Основные особенности CatBoostRegressor***: \n",
    "\n",
    "1. Автоматическая обработка категориальных признаков : CatBoost может работать с категориальными признаками напрямую.\n",
    "2. Снижение переобучения : CatBoost использует методы, такие как перестановочный тест и порядковое целевое кодирование.\n",
    "3. Высокая скорость обучения : Библиотека оптимизирована для быстрого обучения даже на больших объемах данных.\n",
    "4. Поддержка многозадачности : CatBoost может обучаться на нескольких задачах одновременно.\n",
    "5. Встроенная кросс-валидация и подбор гиперпараметров .\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b337d89d-e0f3-4c9c-8c9f-d54af88de5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 42886.0207994\ttotal: 589us\tremaining: 58.3ms\n",
      "10:\tlearn: 19853.9653757\ttotal: 4.82ms\tremaining: 39ms\n",
      "20:\tlearn: 12243.5232824\ttotal: 8.83ms\tremaining: 33.2ms\n",
      "30:\tlearn: 10189.5012866\ttotal: 12.4ms\tremaining: 27.5ms\n",
      "40:\tlearn: 9563.6000890\ttotal: 16ms\tremaining: 23.1ms\n",
      "50:\tlearn: 9377.5232531\ttotal: 18.6ms\tremaining: 17.8ms\n",
      "60:\tlearn: 9264.5780571\ttotal: 21.2ms\tremaining: 13.5ms\n",
      "70:\tlearn: 9175.6445000\ttotal: 24ms\tremaining: 9.81ms\n",
      "80:\tlearn: 9090.1512043\ttotal: 27.3ms\tremaining: 6.4ms\n",
      "90:\tlearn: 9034.3517177\ttotal: 30.8ms\tremaining: 3.04ms\n",
      "99:\tlearn: 8932.6403693\ttotal: 33.9ms\tremaining: 0us\n",
      "RMSE: 10385.31\n",
      "Area: 91.7645\n",
      "NumRooms: 1.7094\n",
      "Age: 6.2366\n",
      "Location: 0.2895\n"
     ]
    }
   ],
   "source": [
    "# Генерация синтетического датасета\n",
    "np.random.seed(42)\n",
    "\n",
    "# Числовые признаки\n",
    "area = np.random.uniform(50, 200, 1000)  # Площадь дома (в квадратных метрах)\n",
    "num_rooms = np.random.randint(1, 6, 1000)  # Количество комнат\n",
    "age = np.random.randint(0, 50, 1000)  # Возраст дома (в годах)\n",
    "\n",
    "# Категориальные признаки\n",
    "location = np.random.choice(['City', 'Suburb', 'Rural'], size=1000)  # Местоположение\n",
    "\n",
    "# Целевая переменная (зависимость от признаков)\n",
    "price = 50000 + area * 1000 - age * 500 + np.random.normal(0, 10000, 1000)  # Цена дома\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Area': area,\n",
    "    'NumRooms': num_rooms,\n",
    "    'Age': age,\n",
    "    'Location': location,\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop(columns=['Price'])\n",
    "y = data['Price']\n",
    "\n",
    "# Указание категориальных признаков\n",
    "categorical_features = ['Location']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание объектов Pool для CatBoost\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=categorical_features)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=categorical_features)\n",
    "\n",
    "# Инициализация модели CatBoostRegressor\n",
    "model = CatBoostRegressor(\n",
    "    iterations=100,        # Количество итераций (деревьев)\n",
    "    depth=6,               # Максимальная глубина дерева\n",
    "    learning_rate=0.1,     # Скорость обучения\n",
    "    loss_function='RMSE',  # Функция потерь для регрессии (Root Mean Squared Error)\n",
    "    verbose=10             # Вывод информации каждые 10 итераций\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(train_pool)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "predictions = model.predict(test_pool)\n",
    "\n",
    "# Оценка качества модели\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Важность признаков\n",
    "feature_importances = model.get_feature_importance()\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b793b-148e-4ef0-a744-7fde823e5cfe",
   "metadata": {},
   "source": [
    "### Задача 3 (3 балла)\n",
    "Решите предыдущую задачу, используя CatBoostRegressor. В качестве прогнозируемого значения используйте столбец RiskScore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee0279-6fcf-4cf9-8975-d3ca3be51790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6957e6a8-0a55-46a7-9c17-305c75641c18",
   "metadata": {},
   "source": [
    "## 3. Стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981ccf0-d073-4484-a2e6-f1d02da0b900",
   "metadata": {},
   "source": [
    "**Стекинг (stacking)** — это продвинутый метод ансамблевого обучения, при котором несколько базовых моделей (\"базовые оценщики\") объединяются для создания более точной модели. Стекинг включает два основных этапа:\n",
    "\n",
    "1. **Обучение базовых моделей**: На этом этапе несколько различных алгоритмов машинного обучения (например, логистическая регрессия, случайный лес, градиентный бустинг и т.д.) обучаются на обучающих данных.\n",
    "   \n",
    "2. **Обучение мета-модели**: Предсказания базовых моделей используются как входные данные для второй модели (мета-модели), которая учится комбинировать их предсказания для получения финального результата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15b80f-d079-4f81-94b2-569af8ed5ba7",
   "metadata": {},
   "source": [
    "Пусть у нас есть $ M $ базовых моделей $ f_1(x), f_2(x), \\dots, f_M(x) $, где каждая модель принимает на вход признаки $ x $ и выдает предсказание. Например:\n",
    "$$\n",
    "f_i(x) = \\hat{y}_i, \\quad i = 1, 2, \\dots, M\n",
    "$$\n",
    "\n",
    "Здесь $ \\hat{y}_i $ — предсказание $ i $-ой базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201058c6-2f7a-4032-ad6e-90bcef85bbf1",
   "metadata": {},
   "source": [
    "Каждая базовая модель обучается на обучающем наборе данных $ D_{\\text{train}} $. Для этого можно использовать любые алгоритмы машинного обучения, такие как линейная регрессия, деревья решений, градиентный бустинг и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af964a-9f51-4ce4-b084-cf4a3e0f3cee",
   "metadata": {},
   "source": [
    "После обучения базовых моделей мы создаем новый набор данных, где каждый объект представляет собой вектор предсказаний всех базовых моделей для данного объекта. Например, если у нас есть $ N $ объектов в обучающей выборке, то новый набор данных будет иметь размерность $ N \\times M $, где $ M $ — количество базовых моделей.\n",
    "\n",
    "Для объекта $ x_j $ новое представление будет выглядеть так:\n",
    "$$\n",
    "z_j = [f_1(x_j), f_2(x_j), \\dots, f_M(x_j)]\n",
    "$$\n",
    "\n",
    "Где $ z_j $ — вектор предсказаний для $ j $-го объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e28c3-7349-4e20-8c9e-5b991e33feeb",
   "metadata": {},
   "source": [
    "Мета-модель (например, линейная регрессия, решающее дерево или нейронная сеть) обучается на новом наборе данных $ Z = \\{z_1, z_2, \\dots, z_N\\} $ и соответствующих истинных значениях целевой переменной $ y $.\n",
    "\n",
    "Мета-модель пытается найти функцию $ g(z) $, которая минимизирует ошибку между предсказанными значениями и истинными значениями:\n",
    "$$\n",
    "g(Z) = \\arg\\min_g \\sum_{j=1}^N L(y_j, g(z_j))\n",
    "$$\n",
    "\n",
    "Где $ L $ — функция потерь (например, среднеквадратичная ошибка для задач регрессии или кросс-энтропия для задач классификации)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4fa76-2c81-438d-8121-e5738cab62f9",
   "metadata": {},
   "source": [
    "Для нового объекта $ x_{\\text{new}} $:\n",
    "1. Каждая базовая модель делает свое предсказание: $ \\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_M $.\n",
    "2. Эти предсказания формируют вектор $ z_{\\text{new}} = [\\hat{y}_1, \\hat{y}_2, \\dots, \\hat{y}_M] $.\n",
    "3. Мета-модель делает финальное предсказание: $ \\hat{y}_{\\text{final}} = g(z_{\\text{new}}) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bcf4f-434a-4b79-984f-e266442081e9",
   "metadata": {},
   "source": [
    "### Задача 4 (1 балл)\n",
    "\n",
    "Решите предыдущую задачу используя стекинг моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44258634-ed61-4165-b216-ae8168f6206d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
