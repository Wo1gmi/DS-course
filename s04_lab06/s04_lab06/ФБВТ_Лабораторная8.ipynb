{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaNHiSxSBukO"
      },
      "source": [
        "# Лабораторная 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYM3sNiAyUwV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from torchvision import transforms as tfs\n",
        "import os\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNLAHnjUhMX"
      },
      "source": [
        "## 1.Свёртка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HABjMBbyU4oP"
      },
      "source": [
        "***Сверточная операция(свёртка)*** в сверточной нейронной сети (CNN) используется для извлечения признаков из входных данных, таких как изображения. Эта операция выполняется с помощью фильтров (ядер).\n",
        "\n",
        "### Двумерная свертка\n",
        "\n",
        "В случае изображений, мы имеем двумерное изображение $I$ с размерностью$H \\times W$ и двумерное ядро (или фильтр) $F$ размерностью $M \\times N$.\n",
        "\n",
        "Двумерная свертка изображения с ядром выполняется путем скольжения фильтра $F$ по изображению и вычисления суммы поэлементных произведений пикселей изображения и элементов фильтра:\n",
        "\n",
        "$(I * F)[i, j]$ = $\\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I[i+m, j+n] \\cdot F[m, n] $\n",
        "\n",
        "Это вычисление содержит операцию свертки. Процесс повторяется для каждой позиции на изображении и в результате получается новая матрица, называемая feature map, которая выявляет определенные признаки изображения.\n",
        "\n",
        "Скорее всего сейчас ***ничего непонятно***, давайте рассмотрим ***пример***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QzDga7gc378"
      },
      "source": [
        "\n",
        "Предположим, у нас есть следующее изображение (представленное в виде матрицы):\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 & 4\\\\\n",
        "2 & 1 & 1 & 3\\\\\n",
        "4 & 3 & 1 & 0\\\\\n",
        "0 & 0 & 1 & 5\\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "$a_{11} = 1, a_{12} = 2, a_{13} = 3, a_{14} = 4, a_{21} = 2$ и т.д\n",
        "\n",
        "И пусть у нас будет следующее ядро свертки (или фильтр):\n",
        "\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "7 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "$b_{11} = 1, b_{12} = 2, b_{21} = 7, b_{22} = 1$\n",
        "\n",
        "Выполним свертку изображения с этим ядром шаг за шагом.\n",
        "\n",
        "Результатом свёртки будет матрица размером 3 $\\times$ 3.\n",
        "\n",
        "\\begin{bmatrix}\n",
        "с_{11} & c_{12} & c_{13}  \\\\\n",
        "c_{21} & c_{22} & c_{23} \\\\\n",
        "c_{31} & c_{32} & c_{33} \\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "$c_{11} = a_{11} * b_{11} + a_{12} * b_{12} + a_{21} * b_{21} + a_{22} * b_{22}$\n",
        "\n",
        "$c_{12} = a_{12} * b_{11} + a_{13} * b_{12} + a_{22} * b_{21} + a_{23} * b_{22}$\n",
        "\n",
        "$c_{13} = a_{13} * b_{11} + a_{14} * b_{12} + a_{23} * b_{21} + a_{24} * b_{22}$\n",
        "\n",
        "$c_{21} = a_{21} * b_{11} + a_{22} * b_{12} + a_{31} * b_{21} + a_{32} * b_{22}$\n",
        "\n",
        "$c_{22} = a_{22} * b_{11} + a_{23} * b_{12} + a_{32} * b_{21} + a_{33} * b_{22}$\n",
        "\n",
        "$c_{23} = a_{23} * b_{11} + a_{24} * b_{12} + a_{33} * b_{21} + a_{34} * b_{22}$\n",
        "\n",
        "$c_{31} = a_{31} * b_{11} + a_{32} * b_{12} + a_{41} * b_{21} + a_{42} * b_{22}$\n",
        "\n",
        "$c_{32} = a_{32} * b_{11} + a_{33} * b_{12} + a_{42} * b_{21} + a_{43} * b_{22}$\n",
        "\n",
        "$c_{33} = a_{33} * b_{11} + a_{34} * b_{12} + a_{43} * b_{21} + a_{44} * b_{22}$\n",
        "\n",
        "Процесс свёртки обычно включает в себя два основных гиперпараметра:\n",
        "\n",
        "- **Размер окна свёртки**: Это размер ядра. В примере выше размер ядра 2$×$2.\n",
        "\n",
        "- **Шаг (Stride)**: Это расстояние между центрами соседних окон ядер. В примере выше stride = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaDmgmZKye75"
      },
      "source": [
        "### Задача1 (1 балл)\n",
        "\n",
        "Дано входное изображение(двумерный тензор):\n",
        "\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 & 4 & 6\\\\\n",
        "2 & 1 & 1 & 3 & 1\\\\\n",
        "4 & 3 & 1 & 0 & 0\\\\\n",
        "0 & 0 & 1 & 5 & 7\\\\\n",
        "3 & 10 & 4 & 5 & 1\\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "Дана свёртка:\n",
        "\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 1\\\\\n",
        "1 & 0 & 1\\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "Примените данную свёртку к изображению."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5xzM2Lgz-Dm"
      },
      "source": [
        "## 2.Pooling\n",
        "\n",
        "Pooling (или пулинг) в сверточных нейронных сетях (CNN) используется для уменьшения размерности признаковых карт, получаемых после сверточных слоев. Он помогает упрощать и концентрировать информацию, уменьшая объем вычислений и сделав модель более устойчивой к масштабным вариациям входных данных.\n",
        "\n",
        "Основные типы пулинга в CNN:\n",
        "\n",
        "1. **Max Pooling**: Для каждой области во входной признаковой карте выбирается максимальное значение. Max pooling помогает выделить самые активные признаки из пространственных областей.\n",
        "\n",
        "2. **Average Pooling**: Для каждой области входной признаковой карты вычисляется среднее значение. Average pooling позволяет усреднить информацию из пространственных областей.\n",
        "\n",
        "Процесс пулинга обычно включает в себя два основных параметра:\n",
        "\n",
        "- **Размер окна пулинга**: Это размер области, для которой вычисляется максимальное или среднее значение. Обычно используются окна размером 2x2 или 3x3.\n",
        "\n",
        "- **Шаг (Stride)**: Это расстояние между центрами соседних окон пулинга. Обычно используется шаг 2, что делает пулинг-слои в полтора раза меньше по размерам.\n",
        "\n",
        "Рассмотрим ***пример:***\n",
        "\n",
        "Исходная матрица:\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 1 & 0 \\\\\n",
        "3 & 2 & 2 & 4 \\\\\n",
        "3 & 2 & 3 & 2 \\\\\n",
        "0 & 1 & 3 & 3 \\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "Применение Max Pooling с окном 2x2 и шагом 2:\n",
        "\n",
        "1. Выбираем первую область 2x2 из исходной матрицы:\n",
        "\\begin{bmatrix}\n",
        " 1 & 1 \\\\\n",
        " 3 & 2 \\\\\n",
        "\\end{bmatrix}\n",
        "Максимальное значение здесь: 3\n",
        "\n",
        "2. Выбираем вторую область 2x2 (с пропуском каждой второй строки и столбца) из исходной матрицы:\n",
        "\\begin{bmatrix}\n",
        " 1 & 0 \\\\\n",
        " 2 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "Максимальное значение здесь: 2\n",
        "\n",
        "3. Выбираем третью область 2x2 (с пропуском каждой второй строки и столбца) из исходной матрицы:\n",
        "\\begin{bmatrix}\n",
        " 3 & 2 \\\\\n",
        " 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "Максимальное значение здесь: 3\n",
        "\n",
        "Таким образом, после применения операции Max Pooling с окном 2x2 и шагом 2 получаем ***новую матрицу***:\n",
        "\\begin{bmatrix}\n",
        " 3 & 2 \\\\\n",
        " 3 & 3 \\\\\n",
        "\\end{bmatrix}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwl3J6HS6mVM"
      },
      "source": [
        "### Задача2 (2 балла)\n",
        "\n",
        "Реализуйте функцию, принимающую на вход матрицу, свёртку для неё(размера 2 на 2) и вычисляющую результат свёртки с stride = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJfUiwIn6SVo"
      },
      "source": [
        "## 3.Пэддинг\n",
        "\n",
        "***Пэддинг (padding)*** - это процесс добавления нулей или других значения по краям входной матрицы в глубоком обучении. Пэддинг обычно используется в сверточных нейронных сетях перед применением операции свертки или пулинга. Основная цель пэддинга состоит в том, чтобы сохранить размерность входных данных или упростить реализацию операций свертки и пулинга."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y73tJUDQ7l7h"
      },
      "source": [
        "### Задача3 (1 балл)\n",
        "\n",
        "Реализуйте функцию, принимающую на вход матрицу и осуществяющую padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG59gV608HEm"
      },
      "source": [
        "## 4.Свёрточная Нейронная сеть\n",
        "\n",
        "Свёрточная нейронная сеть (Convolutional Neural Network, CNN) - это особый вид нейронных сетей, разработанный для обработки и анализа многомерных данных, таких как изображения. CNN успешно применяются в компьютерном зрении, распознавании образов, анализе временных рядов и других областях, где важна обработка многомерных данных.\n",
        "\n",
        "Основные компоненты свёрточной нейронной сети:\n",
        "1. **Сверточный слой (Convolutional Layer)**: Этот слой выполняет операцию свертки, когда ядро фильтра применяется к входным данным для извлечения признаков.\n",
        "2. **Пулинговый слой (Pooling Layer)**: Данный слой уменьшает размерность пространства признаков путем объединения (например, максимум или среднее значения в каждой области).\n",
        "3. **Полносвязные слои (Fully Connected Layers)**: Эти слои используются для принятия решений на основе признаков, извлеченных предыдущими слоями.\n",
        "4. **Функции активации (Activation Functions)**: Обычно применяются функции активации, такие как ReLU (Rectified Linear Unit), чтобы вводить нелинейность в сеть и улучшить ее способность обобщения.\n",
        "\n",
        "Преимущества свёрточных нейронных сетей:\n",
        "1. **Работа с пространственной структурой данных**: CNN способны учитывать пространственную локальность и общие закономерности во входных данных, таких как пиксели изображений.\n",
        "2. **Работа с сокращенной размерностью**: Пулинговые слои позволяют уменьшить размерность пространства признаков, упрощая задачу обработки.\n",
        "3. **Способность извлекать признаки**: Свёрточные слои способны извлекать локальные признаки из входных данных, позволяя сети автоматически выявлять особенности в данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2vVajqaPR9H",
        "outputId": "0f6a6a65-c0d3-4661-cba0-76f3cbb454bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 85762725.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 29785024.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23144159.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5325839.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_tfs = tfs.Compose([\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "# install for train and test\n",
        "root = './'\n",
        "train_dataset = MNIST(root, train=True,  transform=data_tfs, download=True)\n",
        "val_dataset  = MNIST(root, train=False, transform=data_tfs, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU4WKjSJQrQV"
      },
      "outputs": [],
      "source": [
        "train_dataloader =  DataLoader(train_dataset, batch_size=128)\n",
        "valid_dataloader =  DataLoader(val_dataset, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQxD4YHiZaS"
      },
      "source": [
        "### Архитектура LeNet\n",
        "\n",
        "***LeNet*** — это структура(архитектура) сверточной нейронной сети, предложенная в 1998 году.\n",
        "\n",
        "***Архитектура***:\n",
        "\n",
        "Входное изображение размером 28(height)$×$28(widht)$×$(1 channel).\n",
        "\n",
        "1. Свёртка1(ядро: 5$×$5, пэддинг: 2, каналов на выходе: 6). ***На выходе:*** 28(height)$×$28(widht)$×$(6 channels)  \n",
        "\n",
        "2. Pooling1(ядро: 2$×$2, stride: 2). ***На выходе:*** 14(height)$×$14(widht)$×$(6 channels)\n",
        "\n",
        "3. Свёртка2(ядро: 5$×$5, пэддинг: 0, каналов на выходе: 16). ***На выходе:*** 10(height)$×$10(widht)$×$(16 channels)\n",
        "\n",
        "4. Pooling2(ядро: 2$×$2, stride: 2). ***На выходе:*** 5(height)$×$5(widht)$×$(16 channels)\n",
        "\n",
        "5. Линейный слой1 (120 нейронов)\n",
        "\n",
        "6. Линейный слой2 (84 нейрона)\n",
        "\n",
        "7. Выходной слой (10 нейронов)\n",
        "\n",
        "После Свёртки1 и Свёртки два следует ***функция активации***.\n",
        "\n",
        "После Pooling2 следует ***flatten***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pRLcLpwMi4"
      },
      "source": [
        "### Параметры LeNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EdcVsbOwTbg"
      },
      "source": [
        "Поскольку обучение нейронной сети это поиск оптимальных параметров, давайте посчитаем количество параметров (весов) LeNet.\n",
        "\n",
        "***Свёртка1***: 6 ядер размера 5$×$5 + 6 параметров bias = ***156***.\n",
        "\n",
        "***Pooling1***: параметров нет!\n",
        "\n",
        "***Свёртка2***: 16 ядер размера 5$×$5$×$6 + 16 параметров bias = ***2416***.\n",
        "\n",
        "***Pooling2***: параметров нет!\n",
        "\n",
        "***Линейный слой1:*** входной слой: 5$×$5$×$16 = 400, выходной: 120. Число параметров 400$×$120 + 120 = ***48120***.\n",
        "\n",
        "***Линейный слой2:*** входной слой: 120, выходной: 84. Число параметров 120$×$84 + 84 = ***10164***.\n",
        "\n",
        "***Выходной слой:*** входной слой: 84, выходной: 10. Число параметров 84$×$10 + 10 = ***850***.\n",
        "\n",
        "***Итоговое число параметров:*** 156 + 2416 + 48120 + 10164 + 850 = ***61706***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_g6JjZVAgla"
      },
      "source": [
        "Реализуем архитектуру на python в виде класса LeNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSX6Rs3WQydO"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # Свёртка1\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding = 2)\n",
        "        # Свёртка2\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # Pooling1\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "        # Pooling2\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "        # Линейный слой1\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        # Линейный слой2\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        # Выходной слой\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Свёртка1 + активация Тангес\n",
        "        x = F.tanh(self.conv1(x))\n",
        "        # Pooling1\n",
        "        x = self.pool1(x)\n",
        "        # Свёртка1 + активация Тангес\n",
        "        x = F.tanh(self.conv2(x))\n",
        "        # Pooling2\n",
        "        x = self.pool2(x)\n",
        "        # Flatten\n",
        "        size_ = int(x.nelement() / x.shape[0])\n",
        "        x = x.view(-1, size_)\n",
        "        # Линейный слой1 + активация Тангес\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        # Линейный слой2 + активация Тангес\n",
        "        x = F.tanh(self.fc2(x))\n",
        "        # Выходной слой\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U82u8sdQ_ve"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Hz0NrRQ8Sm"
      },
      "outputs": [],
      "source": [
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACt1q1rd9C5A"
      },
      "source": [
        "***Обратите внимание!*** Мы используем .to(device), что означает, что мы перемещаем наши объекты на GPU и обучаемся там же."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbaLJgvWRFUu",
        "outputId": "5369f770-32dd-4caa-a6a6-f90b646a3b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Loader: train. Accuracy: 0.9143833333333333\n",
            "Loader: valid. Accuracy: 0.9705\n",
            "Epoch: 2\n",
            "Loader: train. Accuracy: 0.9746833333333333\n",
            "Loader: valid. Accuracy: 0.9783\n",
            "Epoch: 3\n",
            "Loader: train. Accuracy: 0.9833\n",
            "Loader: valid. Accuracy: 0.9792\n",
            "Epoch: 4\n",
            "Loader: train. Accuracy: 0.9875\n",
            "Loader: valid. Accuracy: 0.9803\n",
            "Epoch: 5\n",
            "Loader: train. Accuracy: 0.9903833333333333\n",
            "Loader: valid. Accuracy: 0.9822\n",
            "Epoch: 6\n",
            "Loader: train. Accuracy: 0.9930333333333333\n",
            "Loader: valid. Accuracy: 0.9813\n",
            "Epoch: 7\n",
            "Loader: train. Accuracy: 0.99485\n",
            "Loader: valid. Accuracy: 0.9806\n",
            "Epoch: 8\n",
            "Loader: train. Accuracy: 0.9956333333333334\n",
            "Loader: valid. Accuracy: 0.9806\n",
            "Epoch: 9\n",
            "Loader: train. Accuracy: 0.9964833333333334\n",
            "Loader: valid. Accuracy: 0.9842\n",
            "Epoch: 10\n",
            "Loader: train. Accuracy: 0.99625\n",
            "Loader: valid. Accuracy: 0.9832\n"
          ]
        }
      ],
      "source": [
        "max_epochs = 10\n",
        "accuracy = {\"train\": [], \"valid\": []}\n",
        "for epoch in range(max_epochs):\n",
        "    for k, dataloader in loaders.items():\n",
        "        epoch_correct = 0\n",
        "        epoch_all = 0\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            if k == \"train\":\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "                outp = model(x_batch.to(device))\n",
        "            else:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outp = model(x_batch.to(device))\n",
        "            preds = outp.argmax(-1)\n",
        "            correct =  (preds == y_batch).sum()\n",
        "            all = y_batch.shape[0]\n",
        "            epoch_correct += correct.item()\n",
        "            epoch_all += all\n",
        "            if k == \"train\":\n",
        "                loss = criterion(outp, y_batch.to(device))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        if k == \"train\":\n",
        "            print(f\"Epoch: {epoch+1}\")\n",
        "        print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n",
        "        accuracy[k].append(epoch_correct/epoch_all)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp45xiLrC-JC"
      },
      "source": [
        "Вспомните, какую точность давали другие алгоритмы на данном датасете. Свёрточная нейронная сеть показала ***лучший*** результат!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKtK4dk7E5iu"
      },
      "source": [
        "### Задача (3 балла)\n",
        "\n",
        "Для датасета CIFAR10, постройте и обучите следующую нейронную сеть.\n",
        "\n",
        "***Архитектура***:\n",
        "\n",
        "Входное изображение размером 32(height)$×$32(widht)$×$(3 channel).\n",
        "\n",
        "1. Свёртка1(ядро: 3$×$3, пэддинг: 0, каналов на выходе: 6). ***На выходе:*** ВАШ ОТВЕТ.  \n",
        "\n",
        "2. Pooling1(ядро: 2$×$2, stride: 2). ***На выходе:*** ВАШ ОТВЕТ.\n",
        "\n",
        "3. Свёртка2(ядро: 3$×$3, пэддинг: 0, каналов на выходе: 12). ***На выходе:*** ВАШ ОТВЕТ.\n",
        "\n",
        "4. Pooling2(ядро: 2$×$2, stride: 2). ***На выходе:*** ВАШ ОТВЕТ.\n",
        "\n",
        "5. Линейный слой1 (256 нейронов)\n",
        "\n",
        "6. Линейный слой2 (128 нейрона)\n",
        "\n",
        "7. Линейный слой3 (64 нейрона)\n",
        "\n",
        "8. Выходной слой (10 нейронов)\n",
        "\n",
        "* После Свёртки1 и Свёртки два следует ***функция активации: ReLU***.\n",
        "\n",
        "* После Pooling2 следует ***flatten***.\n",
        "\n",
        "***Сколько параметров имеет данная архитектура?*** ВАШ ОТВЕТ.\n",
        "\n",
        "Если всё сделает правильно, то легко получите точность выше 60 на 10 эпохах!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N42JWWSw9wbU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yroqggIuWLo2"
      },
      "source": [
        "### Архитектура AlexNet\n",
        "\n",
        "Рассмотрите файл(AlexNet) во вложении.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7_06X66AQ1w"
      },
      "source": [
        "### Задача 5(3 балла)\n",
        "\n",
        "Реализуйте класс, соответствующий архитектуре AlexNet"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}